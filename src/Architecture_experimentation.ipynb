{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO5K+HDuOcz0rSu2eshXRPl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kSNr3cWzDK9Y","executionInfo":{"status":"ok","timestamp":1715590210234,"user_tz":-120,"elapsed":19307,"user":{"displayName":"Tobias Lindenbauer","userId":"10361173233973415805"}},"outputId":"da2f3bbf-77a7-4808-c490-e46237f57f1c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/nlp_ss24/multilingual-lexical-simplification')\n","sys.path.append('/content/drive/MyDrive/nlp_ss24/multilingual-lexical-simplification/src')"],"metadata":{"id":"nKbKg35RESMm","executionInfo":{"status":"ok","timestamp":1715590212274,"user_tz":-120,"elapsed":246,"user":{"displayName":"Tobias Lindenbauer","userId":"10361173233973415805"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"tCkCeAkOC38M","executionInfo":{"status":"ok","timestamp":1715590754937,"user_tz":-120,"elapsed":260,"user":{"displayName":"Tobias Lindenbauer","userId":"10361173233973415805"}}},"outputs":[],"source":["from lexical_simplifier import LexicalSimplifier\n","\n","\n","class GermanBertLexicalSimplifier(LexicalSimplifier):\n","    \"\"\"\n","    A German BERT based implementation of lexical simplification. Masks the given complex word with [MASK], adds other\n","    BERT specific tokens and generates a list of possible substitutions via the model predictions based on the prompt.\n","    \"\"\"\n","\n","    def __init__(self, model, pattern, exemplars):\n","        super().__init__(model, pattern, exemplars)\n","\n","    def generate_substitutions_for(self, complex_word):\n","        \"\"\"Generates a list of substitutions via the model predictions for the given complex word.\"\"\"\n","        raise NotImplementedError(\"Please implement this method in the subclass.\")"]},{"cell_type":"code","source":["from transformers import AutoModelForMaskedLM, AutoTokenizer\n","import torch\n","\n","# Load the tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-german-cased\")\n","model = AutoModelForMaskedLM.from_pretrained(\"dbmdz/bert-base-german-cased\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1NDZFYOMxnh","executionInfo":{"status":"ok","timestamp":1715591149528,"user_tz":-120,"elapsed":3307,"user":{"displayName":"Tobias Lindenbauer","userId":"10361173233973415805"}},"outputId":"5069b3ad-bb64-4290-afd3-a2531b27e777"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at dbmdz/bert-base-german-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["# Input text with a [MASK] token\n","bert_pattern = '{original_sentence} Die einfachere Version der vorigen Satzes ist: {sentence_with_complex_word_masked}'\n","text = 'Der Fluss wurde begradigt um mehr Baufläche zu schaffen.'\n","text_masked = 'Der Fluss wurde [MASK] um mehr Baufläche zu schaffen.'\n","\n","input_text = bert_pattern.format(original_sentence=text, sentence_with_complex_word_masked)\n","\n","# Tokenize input text\n","inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n","\n","# Forward pass through the model\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","\n","# Get predicted probabilities for the masked token\n","masked_index = inputs[\"input_ids\"].squeeze().tolist().index(tokenizer.mask_token_id)\n","probs = torch.nn.functional.softmax(outputs.logits[0, masked_index], dim=-1)\n","\n","# Get the top predictions\n","top_k = 5\n","top_k_tokens = torch.topk(probs, k=top_k).indices.tolist()\n","\n","# Convert token IDs back to tokens\n","predicted_tokens = [tokenizer.decode(token).strip() for token in top_k_tokens]\n","\n","print(\"Predicted tokens:\", predicted_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SWzCf4nSLX9T","executionInfo":{"status":"ok","timestamp":1715591442638,"user_tz":-120,"elapsed":846,"user":{"displayName":"Tobias Lindenbauer","userId":"10361173233973415805"}},"outputId":"a9935e02-7c0c-45d8-a183-5b18c953da1b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted tokens: ['gebaut', 'ausgebaut', 'angelegt', 'verlegt', 'vergrößert']\n"]}]}]}