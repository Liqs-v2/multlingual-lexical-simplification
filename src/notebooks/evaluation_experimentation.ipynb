{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/nlp_ss24/multilingual-lexical-simplification')\n",
    "sys.path.append('/content/drive/MyDrive/nlp_ss24/multilingual-lexical-simplification/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-german-cased\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"dbmdz/bert-base-german-cased\")\n",
    "\n",
    "# Specify the patter to use for this lexical simplifier\n",
    "bert_pattern = '{original_sentence} Die einfachere Version der vorigen Satzes ist: {sentence_with_complex_word_masked}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from german_bert_lexical_simplifier import GermanBertLexicalSimplifier\n",
    "german_bert_ls = GermanBertLexicalSimplifier(model, tokenizer, bert_pattern, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.process_BenchLS import process_BenchLS\n",
    "eval_data = process_BenchLS('/content/drive/MyDrive/nlp_ss24/multilingual-lexical-simplification/data/BenchLS.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test evaluation on the first datasample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The metrics are inspired by the BenchLS Paper, they do not take into account the ranks of the predictions\n",
    "# Potential: Proportion of instances in which at least one of the candidates generated is in the gold-standard.\n",
    "# Precision: Proportion of generated substitutions that are in the gold-standard.\n",
    "# Recall: The proportion of gold-standard substitutions that are among the generated substitutions.\n",
    "# F1: The harmonic mean of precision and recall.\n",
    "\n",
    "sample = eval_data[0]\n",
    "print(f\"This is the sample: {sample}\")\n",
    "\n",
    "predicted_tokens = german_bert_ls.generate_substitutions_for(sample[1], sample[0])\n",
    "print(f\"These are the predicted tokens: {predicted_tokens}\")\n",
    "\n",
    "sample_potential = False\n",
    "sample_precision = 0\n",
    "sample_recall = 0\n",
    "sample_f1 = 0\n",
    "\n",
    "# Flatten the dict of gold standard substitutions\n",
    "gold_standard_substitutions = [word for sublist in sample[3].values() for word in sublist]\n",
    "\n",
    "# Check Potential & count Precision\n",
    "for prediction in predicted_tokens:\n",
    "    if any(prediction == values for values in gold_standard_substitutions):\n",
    "        sample_potential = True\n",
    "        sample_precision += 1\n",
    "sample_precision = sample_precision / len(predicted_tokens)\n",
    "\n",
    "# Calculate Recall\n",
    "true_positives = sum(1 for token in gold_standard_substitutions if token in predicted_tokens)\n",
    "sample_recall = true_positives / len(gold_standard_substitutions) if gold_standard_substitutions else 0\n",
    "\n",
    "# Calculate F1\n",
    "if sample_precision + sample_recall != 0:\n",
    "    sample_f1 = 2 * (sample_precision * sample_recall) / (sample_precision + sample_recall)\n",
    "\n",
    "print(\"Potential: \", sample_potential)\n",
    "print(\"Precision: \", sample_precision)\n",
    "print(\"Recall: \", sample_recall)\n",
    "print(\"F1: \", sample_f1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
