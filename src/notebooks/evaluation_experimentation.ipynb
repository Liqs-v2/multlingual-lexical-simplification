{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42036,"status":"ok","timestamp":1717254836052,"user":{"displayName":"Luis Wiedmann","userId":"10160208935737893738"},"user_tz":-120},"id":"pcdIhYd6KWBl","outputId":"e00d6adb-aaa7-4186-f7be-420cbfdc81f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":206,"status":"ok","timestamp":1717254859496,"user":{"displayName":"Luis Wiedmann","userId":"10160208935737893738"},"user_tz":-120},"id":"Owxjwke5S2Ud"},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":210,"status":"ok","timestamp":1717254861848,"user":{"displayName":"Luis Wiedmann","userId":"10160208935737893738"},"user_tz":-120},"id":"xI6g7WXcKWBn"},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/nlp_ss24/multilingual-lexical-simplification')\n","sys.path.append('/content/drive/MyDrive/nlp_ss24/multilingual-lexical-simplification/src')"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1013,"status":"ok","timestamp":1717255818429,"user":{"displayName":"Luis Wiedmann","userId":"10160208935737893738"},"user_tz":-120},"id":"uKUOngKNKWBo","outputId":"c0c08c28-b031-4463-c957-230c028c67f2"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at google-bert/bert-base-german-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from transformers import AutoModelForMaskedLM, AutoTokenizer\n","\n","# Load the tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-german-cased\")\n","model = AutoModelForMaskedLM.from_pretrained(\"google-bert/bert-base-german-cased\")\n","\n","# Specify the patter to use for this lexical simplifier\n","bert_pattern = '{original_sentence} Die vereinfachte Version des vorigen Satzes ist: {sentence_with_complex_word_masked}'"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1717255829320,"user":{"displayName":"Luis Wiedmann","userId":"10160208935737893738"},"user_tz":-120},"id":"xuhHS5bjKWBo","outputId":"5d1802a4-2e2a-4907-cbae-cb6f3929f4fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["No exemplars provided, using zero-shot mode.\n"]}],"source":["from simple_bert_lexical_simplifier import SimpleBertLexicalSimplifier\n","bert_ls = SimpleBertLexicalSimplifier(model, tokenizer, bert_pattern, None)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47310,"status":"ok","timestamp":1717255878514,"user":{"displayName":"Luis Wiedmann","userId":"10160208935737893738"},"user_tz":-120},"id":"em_Wxy2fGYOq","outputId":"976f9ced-1055-45b8-a1df-3746deeb4c50"},"outputs":[{"name":"stdout","output_type":"stream","text":["Benchmarking model on EN ...\n","Benchmarking model on BenchLSDataProvider...\n"]},{"name":"stderr","output_type":"stream","text":["Benchmarking: 100%|██████████| 929/929 [00:17<00:00, 54.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Benchmarking model on LexMTurkDataProvider...\n"]},{"name":"stderr","output_type":"stream","text":["Benchmarking: 100%|██████████| 500/500 [00:07<00:00, 64.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Benchmarking model on NNSevalDataProvider...\n"]},{"name":"stderr","output_type":"stream","text":["Benchmarking: 100%|██████████| 239/239 [00:03<00:00, 67.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Benchmarking model on TsarENDataProvider...\n"]},{"name":"stderr","output_type":"stream","text":["Benchmarking: 100%|██████████| 386/386 [00:06<00:00, 63.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Benchmarking model on DE ...\n","Benchmarking model on GermanEvalDataProvider...\n"]},{"name":"stderr","output_type":"stream","text":["Benchmarking: 100%|██████████| 1040/1040 [00:12<00:00, 82.73it/s]\n"]}],"source":["from benchmark_suite import BenchmarkSuite\n","from language import Language\n","suite = BenchmarkSuite(bert_ls, {Language.EN: '{original_sentence} The simpler version of the previous sentence is: {sentence_with_complex_word_masked}',\n","                                 Language.DE: '{original_sentence} Die vereinfachte Version des vorigen Satzes ist: {sentence_with_complex_word_masked}',\n","                                 Language.ES: '{original_sentence} La versión simplificada de la frase anterior es: {sentence_with_complex_word_masked}'})\n","suite.run()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
